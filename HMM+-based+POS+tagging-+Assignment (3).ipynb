{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the datset into training and test sets. Training =95% Testing=5%\n",
    "train_set,test_set = train_test_split(nltk_data,train_size=0.95,test_size=0.05,random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95547\n",
      "5129\n"
     ]
    }
   ],
   "source": [
    "#List of train and test tagged words\n",
    "train_tagged_words = [w for word in train_set for w in word]\n",
    "test_tagged_words = [w[0] for word in test_set for w in word]\n",
    "print(len(train_tagged_words))\n",
    "print(len(test_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('confirmed', 'VERB'), ('the', 'DET'), ('filing', 'NOUN'), ('but', 'CONJ')]\n"
     ]
    }
   ],
   "source": [
    "#Printing few words in train set\n",
    "print(train_tagged_words[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['company', 'said', '0', 'it']\n"
     ]
    }
   ],
   "source": [
    "#Printing few words in test set\n",
    "print(test_tagged_words[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12100\n"
     ]
    }
   ],
   "source": [
    "#Length of Unique tags and vocabulary check\n",
    "tags = {tag for word,tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "vocab = {word for word,tag in train_tagged_words}\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have completed the basic steps and basis checks needed in order to perform the POS tagging so lets use Viterbi Algorithm for POS tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla Viterbi POS tagger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Emission Probablity\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transition Probability\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VERB</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRT</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>.</th>\n",
       "      <th>ADV</th>\n",
       "      <th>DET</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>X</th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.169249</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.022851</td>\n",
       "      <td>0.030674</td>\n",
       "      <td>0.110070</td>\n",
       "      <td>0.034934</td>\n",
       "      <td>0.081952</td>\n",
       "      <td>0.134392</td>\n",
       "      <td>0.064988</td>\n",
       "      <td>0.217506</td>\n",
       "      <td>0.035786</td>\n",
       "      <td>0.092022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.156671</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.039981</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.349140</td>\n",
       "      <td>0.034868</td>\n",
       "      <td>0.055323</td>\n",
       "      <td>0.121339</td>\n",
       "      <td>0.118085</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.058113</td>\n",
       "      <td>0.052534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.018761</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>0.026504</td>\n",
       "      <td>0.350208</td>\n",
       "      <td>0.117332</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.210542</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.036033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.405272</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.056672</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.247776</td>\n",
       "      <td>0.043822</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>0.097858</td>\n",
       "      <td>0.083031</td>\n",
       "      <td>0.013509</td>\n",
       "      <td>0.017792</td>\n",
       "      <td>0.020099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.147667</td>\n",
       "      <td>0.042666</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>0.043397</td>\n",
       "      <td>0.263564</td>\n",
       "      <td>0.240604</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>0.012248</td>\n",
       "      <td>0.029175</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.176514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.089095</td>\n",
       "      <td>0.057538</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.222242</td>\n",
       "      <td>0.093320</td>\n",
       "      <td>0.052324</td>\n",
       "      <td>0.173335</td>\n",
       "      <td>0.043963</td>\n",
       "      <td>0.026971</td>\n",
       "      <td>0.066349</td>\n",
       "      <td>0.091342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.343491</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.030474</td>\n",
       "      <td>0.014243</td>\n",
       "      <td>0.031467</td>\n",
       "      <td>0.137131</td>\n",
       "      <td>0.080490</td>\n",
       "      <td>0.069891</td>\n",
       "      <td>0.129182</td>\n",
       "      <td>0.023186</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>0.118582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.039850</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.022220</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.638087</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.012438</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.204323</td>\n",
       "      <td>0.045405</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.009540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.011699</td>\n",
       "      <td>0.016971</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.010710</td>\n",
       "      <td>0.699621</td>\n",
       "      <td>0.063931</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.066403</td>\n",
       "      <td>0.021091</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.078267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.203851</td>\n",
       "      <td>0.010662</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.185232</td>\n",
       "      <td>0.062381</td>\n",
       "      <td>0.163590</td>\n",
       "      <td>0.024984</td>\n",
       "      <td>0.054742</td>\n",
       "      <td>0.017187</td>\n",
       "      <td>0.076384</td>\n",
       "      <td>0.055538</td>\n",
       "      <td>0.142584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.485452</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.013017</td>\n",
       "      <td>0.210949</td>\n",
       "      <td>0.040965</td>\n",
       "      <td>0.034074</td>\n",
       "      <td>0.009954</td>\n",
       "      <td>0.073124</td>\n",
       "      <td>0.089969</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.022971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.062226</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.320967</td>\n",
       "      <td>0.039025</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.324709</td>\n",
       "      <td>0.107024</td>\n",
       "      <td>0.034427</td>\n",
       "      <td>0.070031</td>\n",
       "      <td>0.016893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          VERB      CONJ       NUM       PRT      NOUN         .       ADV  \\\n",
       "VERB  0.169249  0.005577  0.022851  0.030674  0.110070  0.034934  0.081952   \n",
       "CONJ  0.156671  0.000465  0.039981  0.004649  0.349140  0.034868  0.055323   \n",
       "NUM   0.018761  0.013699  0.184932  0.026504  0.350208  0.117332  0.002978   \n",
       "PRT   0.405272  0.002306  0.056672  0.001647  0.247776  0.043822  0.010214   \n",
       "NOUN  0.147667  0.042666  0.009542  0.043397  0.263564  0.240604  0.017074   \n",
       ".     0.089095  0.057538  0.081003  0.002427  0.222242  0.093320  0.052324   \n",
       "ADV   0.343491  0.006956  0.030474  0.014243  0.031467  0.137131  0.080490   \n",
       "DET   0.039850  0.000483  0.022220  0.000242  0.638087  0.017993  0.012438   \n",
       "ADJ   0.011699  0.016971  0.021256  0.010710  0.699621  0.063931  0.004778   \n",
       "X     0.203851  0.010662  0.002864  0.185232  0.062381  0.163590  0.024984   \n",
       "PRON  0.485452  0.005360  0.006508  0.013017  0.210949  0.040965  0.034074   \n",
       "ADP   0.008340  0.000962  0.062226  0.001390  0.320967  0.039025  0.014006   \n",
       "\n",
       "           DET       ADJ         X      PRON       ADP  \n",
       "VERB  0.134392  0.064988  0.217506  0.035786  0.092022  \n",
       "CONJ  0.121339  0.118085  0.008833  0.058113  0.052534  \n",
       "NUM   0.003276  0.034247  0.210542  0.001489  0.036033  \n",
       "PRT   0.097858  0.083031  0.013509  0.017792  0.020099  \n",
       "NOUN  0.012942  0.012248  0.029175  0.004607  0.176514  \n",
       ".     0.173335  0.043963  0.026971  0.066349  0.091342  \n",
       "ADV   0.069891  0.129182  0.023186  0.014906  0.118582  \n",
       "DET   0.005676  0.204323  0.045405  0.003744  0.009540  \n",
       "ADJ   0.004943  0.066403  0.021091  0.000330  0.078267  \n",
       "X     0.054742  0.017187  0.076384  0.055538  0.142584  \n",
       "PRON  0.009954  0.073124  0.089969  0.007657  0.022971  \n",
       "ADP   0.324709  0.107024  0.034427  0.070031  0.016893  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vanilla Viterbi Heuristic\n",
    "\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'),\n",
       "  ('Contra', 'NOUN'),\n",
       "  ('military', 'ADJ'),\n",
       "  ('command', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('in', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('statement', 'NOUN'),\n",
       "  ('from', 'ADP'),\n",
       "  ('Honduras', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('Sandinista', 'NOUN'),\n",
       "  ('troops', 'NOUN'),\n",
       "  ('had', 'VERB'),\n",
       "  ('launched', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('major', 'ADJ'),\n",
       "  ('offensive', 'NOUN'),\n",
       "  ('against', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('rebel', 'NOUN'),\n",
       "  ('forces', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('*-1', 'X'),\n",
       "  ('Bucking', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('market', 'NOUN'),\n",
       "  ('trend', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('an', 'DET'),\n",
       "  ('issue', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('$', '.'),\n",
       "  ('130', 'NUM'),\n",
       "  ('million', 'NUM'),\n",
       "  ('*U*', 'X'),\n",
       "  ('general', 'ADJ'),\n",
       "  ('obligation', 'NOUN'),\n",
       "  ('distributable', 'ADJ'),\n",
       "  ('state', 'NOUN'),\n",
       "  ('aid', 'NOUN'),\n",
       "  ('bonds', 'NOUN'),\n",
       "  ('from', 'ADP'),\n",
       "  ('Detroit', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('Mich.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('apparently', 'ADV'),\n",
       "  ('drew', 'VERB'),\n",
       "  ('solid', 'ADJ'),\n",
       "  ('investor', 'NOUN'),\n",
       "  ('interest', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Ralston', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('its', 'PRON'),\n",
       "  ('Eveready', 'NOUN'),\n",
       "  ('battery', 'NOUN'),\n",
       "  ('unit', 'NOUN'),\n",
       "  ('was', 'VERB'),\n",
       "  ('hurt', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('by', 'ADP'),\n",
       "  ('continuing', 'VERB'),\n",
       "  ('economic', 'ADJ'),\n",
       "  ('problems', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('South', 'NOUN'),\n",
       "  ('America', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('I', 'PRON'),\n",
       "  ('feel', 'VERB'),\n",
       "  ('pretty', 'ADV'),\n",
       "  ('good', 'ADJ'),\n",
       "  ('about', 'ADP'),\n",
       "  ('it', 'PRON'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NOUN'),\n",
       "  ('Felten', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  (',', '.'),\n",
       "  ('``', '.'),\n",
       "  ('We', 'PRON'),\n",
       "  ('got', 'VERB'),\n",
       "  ('what', 'PRON'),\n",
       "  ('*T*-252', 'X'),\n",
       "  ('amounted', 'VERB'),\n",
       "  ('to', 'PRT'),\n",
       "  ('a', 'DET'),\n",
       "  ('parking', 'NOUN'),\n",
       "  ('ticket', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('by', 'ADP'),\n",
       "  ('*-1', 'X'),\n",
       "  ('complaining', 'VERB'),\n",
       "  ('about', 'ADP'),\n",
       "  ('it', 'PRON'),\n",
       "  (',', '.'),\n",
       "  ('we', 'PRON'),\n",
       "  ('ended', 'VERB'),\n",
       "  ('up', 'PRT'),\n",
       "  ('with', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('sizable', 'ADJ'),\n",
       "  ('fine', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('suspension', 'NOUN'),\n",
       "  ('.', '.'),\n",
       "  (\"''\", '.')]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose the random seed value as 1234\n",
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sentences\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sentences\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "test_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken is:  34.879995822906494\n"
     ]
    }
   ],
   "source": [
    "# Time taken\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken is: \",difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained is:  91.1504424778761\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = (len(check)/len(tagged_seq))*100\n",
    "print(\"Accuracy obtained is: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_tagged_cases = [j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Contra', 'VERB'), ('Contra', 'NOUN')),\n",
       " (('command', 'VERB'), ('command', 'NOUN')),\n",
       " (('Honduras', 'VERB'), ('Honduras', 'NOUN')),\n",
       " (('Sandinista', 'VERB'), ('Sandinista', 'NOUN')),\n",
       " (('offensive', 'VERB'), ('offensive', 'NOUN')),\n",
       " (('rebel', 'VERB'), ('rebel', 'NOUN')),\n",
       " (('forces', 'VERB'), ('forces', 'NOUN')),\n",
       " (('Eveready', 'VERB'), ('Eveready', 'NOUN')),\n",
       " (('*T*-252', 'VERB'), ('*T*-252', 'X')),\n",
       " (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above words are incorrectly tagged with Vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified Viterbi Algorithm - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Modified Viterbi Algorithm - 1, Vanilla Viterbi is modified such that if unknown word is present, we only use transition probability when emission probability is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the case of unknown words, use transition probability when emission probability is zero.\n",
    "\n",
    "def Viterbi_modified_1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "      \n",
    "        # If Probability == zero (occurence of unknown word) -> transition probability is used\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]\n",
    "                           \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken is:  28.946441411972046\n",
      "Accuracy obtained is:  94.69026548672566\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_modified_1(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken is: \",difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print(\"Accuracy obtained is: \",accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('command', 'VERB'), ('command', 'NOUN')),\n",
       " (('Honduras', 'DET'), ('Honduras', 'NOUN')),\n",
       " (('Sandinista', 'VERB'), ('Sandinista', 'NOUN')),\n",
       " (('Eveready', 'VERB'), ('Eveready', 'NOUN')),\n",
       " (('*T*-252', 'VERB'), ('*T*-252', 'X')),\n",
       " (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Incorrectly tagged words after Technique-1\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to Vanilla Viterbi, Modified Viterbi 1 tagged few words correctly such as: Contra, rebel, offensive and forces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified Viterbi Algorithm - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this algorithm, the unknown words are identified using rule based tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patterns used for tagging\n",
    "pattern = [\n",
    "    (r'.*ing$', 'VERB'),              \n",
    "    (r'.*ed$', 'VERB'),                \n",
    "    (r'.*es$', 'VERB'),                  \n",
    "    (r'.*\\'s$', 'NOUN'),              \n",
    "    (r'.*s$', 'NOUN'),                \n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        \n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), \n",
    "    (r'.*', 'NOUN')                   \n",
    "]\n",
    "\n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule based tagger is used in case of occurence of an unknown word\n",
    "def Viterbi_modified_2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1]       \n",
    "       \n",
    "        \n",
    "        if(pmax==0):\n",
    "            state_max = rule_based_tagger.tag([word])[0][1] \n",
    "        else:\n",
    "            if state_max != 'X':\n",
    "                state_max = T[p.index(pmax)]                \n",
    "            \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken is:  28.451680183410645\n",
      "Accuracy obtained is:  97.34513274336283\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_modified_2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "\n",
    "print(\"Time taken is: \",difference)\n",
    "print(\"Accuracy obtained is: \",accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('command', 'VERB'), ('command', 'NOUN')),\n",
       " (('drew', 'NOUN'), ('drew', 'VERB')),\n",
       " (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Incorrectly tagged words after Technique-2\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to Vanilla Viterbi, Modified Viterbi 2 tagged few words correctly such as: Contra, Honduras, Sandinista, offensive, rebel, forces, *T*-252, and eveready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to Modified Viterbi 1, Modified Viterbi 2 tagged few words correctly such as: Honduras, Sandinista, T-252 and eveready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tagged words\n",
    "test_run_base_full = [tup for sent in test_set for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words_full = [tup[0] for sent in test_set for tup in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla Viterbi Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  1272.6303236484528\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words_full)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained is:  92.12322090076039\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base_full) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print(\"Accuracy obtained is: \",accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modified Viterbi technique 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  1233.4011788368225\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi_modified_1(test_tagged_words_full)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained is:  94.03392474166505\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base_full) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print(\"Accuracy obtained is: \",accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modified Viterbi technique 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  1207.428570985794\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi_modified_2(test_tagged_words_full)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained is:  95.37921622148568\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base_full) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print(\"Accuracy obtained is: \",accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS using Viterbi and modified Viterbi on Sample test cases given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_sentences = [\"Android is a mobile operating system developed by Google.\",\n",
    "\"Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.\",\n",
    "\"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\",\n",
    "\"Twitter is an online news and social networking service on which users post and interact with messages known as tweets.\",\n",
    "\"Before entering politics, Donald Trump was a domineering businessman and a television personality.\",\n",
    "\"The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.\",\n",
    "\"This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.\",\n",
    "\"Show me the cheapest round trips from Dallas to Atlanta\",\n",
    "\"I would like to see flights from Denver to Philadelphia.\",\n",
    "\"Show me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.\",\n",
    "\"NASA invited social media users to experience the launch of ICESAT-2 Satellite.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_words = [w for sent in Test_sentences for w in sent.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla Viterbi on sample test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  38.2150297164917\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq = Viterbi(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'VERB'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'VERB'),\n",
       " ('Android', 'VERB'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'VERB'),\n",
       " ('worldwide', 'VERB'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'VERB'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'VERB'),\n",
       " ('Google', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'VERB'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'VERB'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'VERB'),\n",
       " ('firehose.', 'VERB'),\n",
       " ('Twitter', 'VERB'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', 'VERB'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', 'VERB'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', 'VERB'),\n",
       " ('known', 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', 'VERB'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', 'VERB'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', 'VERB'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', 'VERB'),\n",
       " ('The', 'DET'),\n",
       " ('2018', 'VERB'),\n",
       " ('FIFA', 'VERB'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'VERB'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', 'VERB'),\n",
       " ('FIFA', 'VERB'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', 'VERB'),\n",
       " ('contested', 'VERB'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', 'VERB'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'ADJ'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', 'VERB'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'ADJ'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', 'VERB'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('I', 'PRON'),\n",
       " ('would', 'VERB'),\n",
       " ('like', 'ADP'),\n",
       " ('to', 'PRT'),\n",
       " ('see', 'VERB'),\n",
       " ('flights', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Denver', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Philadelphia.', 'VERB'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('price', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('flights', 'NOUN'),\n",
       " ('leaving', 'VERB'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('about', 'ADP'),\n",
       " ('3', 'NUM'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('afternoon', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('arriving', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('San', 'NOUN'),\n",
       " ('Francisco.', 'VERB'),\n",
       " ('NASA', 'VERB'),\n",
       " ('invited', 'VERB'),\n",
       " ('social', 'ADJ'),\n",
       " ('media', 'NOUN'),\n",
       " ('users', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('experience', 'NOUN'),\n",
       " ('the', 'DET'),\n",
       " ('launch', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('ICESAT-2', 'VERB'),\n",
       " ('Satellite.', 'VERB')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tagged_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modified Viterbi technique 1 on sample test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  39.75897264480591\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq2 = Viterbi_modified_1(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'DET'),\n",
       " ('Android', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'NOUN'),\n",
       " ('worldwide', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'DET'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'DET'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'DET'),\n",
       " ('Google', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'DET'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'X'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'VERB'),\n",
       " ('firehose.', 'X'),\n",
       " ('Twitter', 'VERB'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', 'NOUN'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', 'DET'),\n",
       " ('known', 'ADJ'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', 'DET'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', 'X'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', 'NOUN'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', 'NOUN'),\n",
       " ('The', 'DET'),\n",
       " ('2018', 'NOUN'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', 'NOUN'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', 'NOUN'),\n",
       " ('contested', 'NOUN'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', 'NOUN'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'ADJ'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', 'DET'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'ADJ'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('I', 'PRON'),\n",
       " ('would', 'VERB'),\n",
       " ('like', 'ADP'),\n",
       " ('to', 'PRT'),\n",
       " ('see', 'VERB'),\n",
       " ('flights', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Denver', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Philadelphia.', 'VERB'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('price', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('flights', 'NOUN'),\n",
       " ('leaving', 'VERB'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('about', 'ADP'),\n",
       " ('3', 'NUM'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('afternoon', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('arriving', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('San', 'NOUN'),\n",
       " ('Francisco.', 'NOUN'),\n",
       " ('NASA', 'NOUN'),\n",
       " ('invited', 'NOUN'),\n",
       " ('social', 'ADJ'),\n",
       " ('media', 'NOUN'),\n",
       " ('users', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('experience', 'NOUN'),\n",
       " ('the', 'DET'),\n",
       " ('launch', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('ICESAT-2', 'DET'),\n",
       " ('Satellite.', 'NOUN')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tagged_seq2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modified Viterbi technique 2 on sample test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  42.17041516304016\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq3 = Viterbi_modified_2(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'NOUN'),\n",
       " ('Android', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'NOUN'),\n",
       " ('worldwide', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'VERB'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'NUM'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'NOUN'),\n",
       " ('Google', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'NUM'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'NOUN'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'NOUN'),\n",
       " ('firehose.', 'NOUN'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', 'NOUN'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', 'VERB'),\n",
       " ('known', 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', 'NOUN'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', 'NOUN'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', 'VERB'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', 'NOUN'),\n",
       " ('The', 'DET'),\n",
       " ('2018', 'NUM'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', 'NOUN'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', 'NOUN'),\n",
       " ('contested', 'VERB'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', 'NOUN'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'ADJ'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', 'NOUN'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'ADJ'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('I', 'PRON'),\n",
       " ('would', 'VERB'),\n",
       " ('like', 'ADP'),\n",
       " ('to', 'PRT'),\n",
       " ('see', 'VERB'),\n",
       " ('flights', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Denver', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Philadelphia.', 'NOUN'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('price', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('flights', 'NOUN'),\n",
       " ('leaving', 'VERB'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('about', 'ADP'),\n",
       " ('3', 'NUM'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('afternoon', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('arriving', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('San', 'NOUN'),\n",
       " ('Francisco.', 'NOUN'),\n",
       " ('NASA', 'NOUN'),\n",
       " ('invited', 'VERB'),\n",
       " ('social', 'ADJ'),\n",
       " ('media', 'NOUN'),\n",
       " ('users', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('experience', 'NOUN'),\n",
       " ('the', 'DET'),\n",
       " ('launch', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('ICESAT-2', 'NOUN'),\n",
       " ('Satellite.', 'NOUN')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tagged_seq3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of Vanilla Viterbi = 92.12%\n",
    "#### Accuracy of Modified Viterbi technique-1 = 94.03%\n",
    "In this technique, transition probability alone is considered for unknown words when emission probability is zero.  \n",
    "#### Accuracy of Modified Viterbi technique-2 = 95.38%\n",
    "In this technique, Rule based taggers are used in cases of unknown words\n",
    "Amongst the modified techniques, rule based taggers used in cases of unknown words has highest accuracy of about 95.4% compared to Vanilla Viterbi having accuracy of about 92%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Words that got incorrectly tagged as a part of Vanilla Viterbi\n",
    "Contra\n",
    "<br>command\n",
    "<br>Honduras\n",
    "<br>Sandinista \n",
    "<br>Eveready\n",
    "<br>T-252 \n",
    "<br>rebel\n",
    "<br>forces\n",
    "<br>up\n",
    "<br>offensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below are the words that got correctly tagged after using modified tecnique -1 as compared to Vanilla Viterbi:\n",
    "Contra as Noun,\n",
    "offensive as Noun,\n",
    "rebel as Noun and forces as Noun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below are the words that got correctly tagged after using modified tecnique -2 as compared to Vanilla Viterbi:\n",
    "Contra as Noun, Honduras as Noun, Sandinista as Noun, offensive as Noun, rebel as Noun, forces as Noun, *T*-252 as X and eveready as Noun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below are the words that got correctly tagged after using modified tecnique -2 as compared to modified technique -1:\n",
    "Honduras as Noun, Sandinista as Noun, T-252 as X and eveready as Noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
